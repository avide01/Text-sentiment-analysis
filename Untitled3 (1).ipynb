{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c656ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_dict = {\n",
    "    \"num\":{ 0: \"sadness\",\n",
    "        1: \"anger\",\n",
    "        2: \"love\",\n",
    "        3: \"surprise\",\n",
    "        4: \"fear\",\n",
    "        5: \"joy\"}\n",
    "}\n",
    "\n",
    "tag_id_dict = {}\n",
    "for key, value in emotions_dict[\"num\"].items():\n",
    "    tag_id_dict[value] = key\n",
    "\n",
    "emotions_dict[\"num\"] = tag_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/NEGIN COMPUTER/Downloads/archive/train.txt', names=['Text', 'label'], delimiter=';')\n",
    "val = pd.read_csv('C:/Users/NEGIN COMPUTER/Downloads/archive/val.txt', names=['Text', 'label'], delimiter=';')\n",
    "test = pd.read_csv('C:/Users/NEGIN COMPUTER/Downloads/archive/test.txt', names=['Text', 'label'], delimiter=';')\n",
    "df = pd.concat([train, val, test])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf81393",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f24f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fc588",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf39c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af002ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = train[train.duplicated() == True].index\n",
    "train.drop(index, axis = 0, inplace = True)\n",
    "train.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = train[train['Text'].duplicated() == True].index\n",
    "train.drop(index, axis = 0, inplace = True)\n",
    "train.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "emotions = df['label'].unique()\n",
    "for emotion in emotions:\n",
    "    text = \" \".join(df[df['label'] == emotion]['Text'])\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                    background_color ='white', \n",
    "                    stopwords = set(nltk.corpus.stopwords.words(\"english\")), \n",
    "                    min_font_size = 10).generate(text)\n",
    "    plt.figure(figsize = (4, 4), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.title(emotion)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def preprocess_data(train, test, val, max_length=None):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(train)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "    if max_length is None:\n",
    "        max_length = max(len(sequence.split()) for sequence in train)\n",
    "\n",
    "    train_sequences = tokenizer.texts_to_sequences(train)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test)\n",
    "    val_sequences = tokenizer.texts_to_sequences(val)\n",
    "\n",
    "    x_train = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "    x_test = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "    x_val = pad_sequences(val_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(\"x_test shape:\", x_test.shape)\n",
    "    print(\"x_val shape:\", x_val.shape)\n",
    "\n",
    "    return x_train, x_test, x_val, vocab_size, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_val, VOCAB_SIZE, tokenizer = preprocess_data(train, test, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_preprocessing(data):\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(data[\"label\"].to_list())\n",
    "    y = y.reshape(-1, 1)\n",
    "    return y\n",
    "\n",
    "y_train = label_preprocessing(train)\n",
    "y_test = label_preprocessing(test)\n",
    "y_val = label_preprocessing(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(VOCAB_SIZE, 64, input_length=30)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(x_train.shape[1],))\n",
    "x = embedding_layer(inputs)\n",
    "x = tf.keras.layers.LSTM(10, return_sequences=True)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "output = tf.keras.layers.Dense(len(encoder.classes_), activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, batch_size=32,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e21d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82829835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict:\n",
    "    def __init__(self, model, tokenizer, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = Tokenizer()\n",
    "    \n",
    "    def predict(self, txt):\n",
    "        x = self.tokenizer.texts_to_sequences([txt])\n",
    "        x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=30)\n",
    "        predictions = self.model.predict(x)\n",
    "        predicted_label_index = np.argmax(predictions[0])\n",
    "        predicted_label = self.emotions_dict[\"num\"][predicted_label_index]\n",
    "        return predicted_label\n",
    "\n",
    "predict = Predict(model, tokenizer, emotions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = Predict(model, tokenizer)\n",
    "predict.predict(\"im so sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b4adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
